# ğŸ“Š AnÃ¡lise Completa - Quasar Analytics

**Data da AnÃ¡lise:** 6 de novembro de 2025  
**Analista:** GitHub Copilot  
**Escopo:** Arquitetura, fluxo de contexto, persistÃªncia e viabilidade de RAG

---

## ğŸ” DIAGNÃ“STICO ATUAL

### âœ… Pontos Fortes

1. **Carregamento de Dados Robusto**
   - âœ… `SheetsLoader` carrega mÃºltiplas planilhas do Google Drive
   - âœ… Suporte a pastas e IDs individuais
   - âœ… Cache em memÃ³ria (`_cache: Dict[str, pd.DataFrame]`)
   - âœ… TTL configurÃ¡vel para recarga automÃ¡tica
   - âœ… Busca avanÃ§ada com extraÃ§Ã£o de IDs e tokens de mÃªs/ano

2. **AgregaÃ§Ãµes DeterminÃ­sticas**
   - âœ… `top_products()` - Top produtos por mÃªs especÃ­fico
   - âœ… `top_products_by_month_all()` - Top produtos para todos os meses
   - âœ… `base_summary()` - Resumo estrutural das planilhas
   - âœ… Parsing de datas, nÃºmeros BR e detecÃ§Ã£o automÃ¡tica de meses

3. **Interface Streamlit Polida**
   - âœ… Design moderno com tema dark
   - âœ… Chat nativo do Streamlit
   - âœ… Sidebar com diagnÃ³sticos detalhados
   - âœ… BotÃ£o para download do snapshot JSON

4. **IntegraÃ§Ã£o com Abacus AI**
   - âœ… Cliente funcional para Gemini via Route-LLM
   - âœ… ConfiguraÃ§Ã£o via `st.secrets` (Cloud) e `.env` (local)
   - âœ… Tratamento de erros HTTP
   - âœ… Timeout configurado (30s)

---

## âŒ PROBLEMAS CRÃTICOS IDENTIFICADOS

### ğŸš¨ 1. **CONTEXTO NÃƒO PERSISTE ENTRE SESSÃ•ES**

**Problema:**
- O cache `_cache` do `SheetsLoader` Ã© armazenado **apenas em memÃ³ria** (`st.session_state`)
- Quando o usuÃ¡rio recarrega a pÃ¡gina ou a sessÃ£o expira, **todo o contexto Ã© perdido**
- Sem embeddings ou vector store, o bot nÃ£o "aprende" ou "lembra" de conversas anteriores

**Impacto:**
- âŒ O bot nÃ£o consegue responder perguntas especÃ­ficas sobre dados jÃ¡ processados apÃ³s reload
- âŒ Recarga das planilhas a cada nova sessÃ£o (lento e ineficiente)
- âŒ Sem memÃ³ria de longo prazo

---

### ğŸš¨ 2. **CONTEXTO LIMITADO POR TOKENS (MAX_TOKENS=1000)**

**Problema no `abacus_client.py`:**
```python
self.max_tokens = int(os.getenv("MAX_TOKENS", "1000"))
```

**Problema no `main.py` (linha ~485):**
```python
# Busca genÃ©rica quando nÃ£o hÃ¡ agregaÃ§Ã£o
if not sheets_ctx:
    rows = loader.search_advanced(last_user_msg, top_k=5)
    sheets_ctx = loader.build_context_snippet(rows)
```

**LimitaÃ§Ãµes:**
- âŒ Apenas **5 linhas** (`top_k=5`) sÃ£o enviadas ao modelo
- âŒ `MAX_TOKENS=1000` Ã© **muito baixo** para respostas elaboradas
- âŒ O contexto Ã© **reconstruÃ­do do zero** a cada pergunta (sem cache semÃ¢ntico)
- âŒ Busca por **keywords simples** (nÃ£o semÃ¢ntica)

**Exemplo:**
Se o usuÃ¡rio pergunta _"Qual foi o produto mais vendido em marÃ§o?"_, o sistema:
1. Detecta "marÃ§o" no texto
2. Usa `search_advanced()` para encontrar 5 linhas com "marÃ§o"
3. Envia essas 5 linhas + pergunta para o modelo
4. **Se a resposta precisa de mais dados, o modelo nÃ£o tem acesso**

---

### ğŸš¨ 3. **SEM RECUPERAÃ‡ÃƒO SEMÃ‚NTICA (RAG)**

**O que falta:**
- âŒ **Embeddings** (vetorizaÃ§Ã£o semÃ¢ntica dos dados)
- âŒ **Vector Store** (Chroma, FAISS, Pinecone, Weaviate)
- âŒ **Similarity Search** (busca por similaridade, nÃ£o keywords)
- âŒ **Reranking** (melhoria da relevÃ¢ncia dos resultados)

**ConsequÃªncias:**
- O bot nÃ£o entende sinÃ´nimos: _"receita"_ vs _"faturamento"_ vs _"valor total"_
- Busca falha com perguntas vagas: _"Me mostre os dados de vendas"_ (muito genÃ©rico)
- NÃ£o consegue conectar informaÃ§Ãµes de mÃºltiplas linhas/abas semanticamente

---

### ğŸš¨ 4. **HISTÃ“RICO DE CONVERSA Ã‰ VOLÃTIL**

**Problema em `main.py` (linha ~470):**
```python
conversation_history = [
    {"role": m["role"], "content": m["content"]}
    for m in st.session_state.messages[:-1]
]
```

**LimitaÃ§Ãµes:**
- âŒ HistÃ³rico sÃ³ existe em `st.session_state.messages` (RAM)
- âŒ Reload da pÃ¡gina = **histÃ³rico perdido**
- âŒ Sem persistÃªncia em banco de dados ou arquivo
- âŒ Sem compressÃ£o/sumarizaÃ§Ã£o de conversas longas (pode estourar limite de tokens)

---

### ğŸš¨ 5. **SISTEMA PROMPT GENÃ‰RICO E LIMITADO**

**Prompt atual em `abacus_client.py`:**
```python
system_text = (
    "VocÃª responde em portuguÃªs e usa a seÃ§Ã£o 'Contexto' quando disponÃ­vel.\n"
    "Siga este protocolo ao responder: 1) entenda a tarefa; 2) localize sinais/dados relevantes no Contexto; 3) calcule/extraia nÃºmeros; 4) redija resposta clara e objetiva com tabela/lista quando fizer sentido.\n"
    "Apenas apresente a resposta final para o usuÃ¡rio; nÃ£o mostre raciocÃ­nio intermediÃ¡rio."
)
```

**Problemas:**
- âŒ Muito vago (nÃ£o explica estrutura dos dados)
- âŒ NÃ£o menciona colunas disponÃ­veis (Data, Produto, Quantidade, Receita_Total, etc.)
- âŒ NÃ£o instrui o modelo a pedir mais contexto quando necessÃ¡rio
- âŒ NÃ£o ensina o modelo a lidar com perguntas ambÃ­guas

---

## ğŸ› ï¸ SOLUÃ‡Ã•ES PROPOSTAS

### ğŸ¯ SoluÃ§Ã£o 1: **Implementar RAG com Vector Store**

#### **Tecnologias Recomendadas:**

| OpÃ§Ã£o | PrÃ³s | Contras | Custo |
|-------|------|---------|-------|
| **ChromaDB** | âœ… Simples, local, open-source<br>âœ… FÃ¡cil integraÃ§Ã£o com Streamlit | âš ï¸ NÃ£o escala para milhÃµes de docs | ğŸ†“ GrÃ¡tis |
| **FAISS** | âœ… Muito rÃ¡pido, otimizado<br>âœ… Usado pelo Meta/Facebook | âš ï¸ Requer mais cÃ³digo manual | ğŸ†“ GrÃ¡tis |
| **Pinecone** | âœ… Cloud, escalÃ¡vel, gerenciado<br>âœ… Alta performance | ğŸ’° Pago apÃ³s cota grÃ¡tis | ğŸ’µ ~$70/mÃªs |
| **Weaviate** | âœ… Open-source, cloud ou local<br>âœ… Suporte a filtros complexos | âš ï¸ Curva de aprendizado | ğŸ†“/ğŸ’µ GrÃ¡tis/Pago |

#### **RecomendaÃ§Ã£o: ChromaDB** (melhor custo-benefÃ­cio para este projeto)

**Arquitetura proposta:**
```
1. Carregamento (SheetsLoader)
   â†“
2. Chunking (dividir dados em blocos semÃ¢nticos)
   â†“
3. Embedding (converter texto â†’ vetores com OpenAI/Gemini/local)
   â†“
4. Armazenamento (ChromaDB persist_directory)
   â†“
5. Retrieval (similarity search)
   â†“
6. Prompt Engineering (injetar resultados no contexto)
   â†“
7. GeraÃ§Ã£o (Abacus/Gemini)
```

#### **ImplementaÃ§Ã£o:**

**Nova dependÃªncia em `requirements.txt`:**
```txt
chromadb==0.4.22
sentence-transformers==2.2.2  # Para embeddings locais
```

**Novo arquivo `app/rag_engine.py`:**
```python
import chromadb
from chromadb.config import Settings
from sentence_transformers import SentenceTransformer
import pandas as pd
from typing import List, Dict, Any

class RAGEngine:
    """Motor de Retrieval-Augmented Generation para o Quasar."""
    
    def __init__(self, persist_dir: str = "./data/chroma_db"):
        # Cliente ChromaDB com persistÃªncia
        self.client = chromadb.Client(Settings(
            chroma_db_impl="duckdb+parquet",
            persist_directory=persist_dir
        ))
        
        # Modelo de embeddings (pode ser substituÃ­do por OpenAI/Gemini)
        self.embedder = SentenceTransformer('all-MiniLM-L6-v2')  # Leve e eficiente
        
        # ColeÃ§Ã£o de vendas
        self.collection = self.client.get_or_create_collection(
            name="vendas",
            metadata={"description": "Dados de vendas do Quasar Analytics"}
        )
    
    def index_dataframes(self, cache: Dict[str, pd.DataFrame]) -> int:
        """Indexa todos os DataFrames do cache em ChromaDB."""
        indexed = 0
        for key, df in cache.items():
            if df.empty:
                continue
            
            sheet_id, ws_title = (key.split("::", 1) + [""])[:2]
            
            for idx, row in df.iterrows():
                # Texto semÃ¢ntico: combina colunas relevantes
                text = self._row_to_text(row, ws_title)
                
                # Metadados para filtros
                metadata = {
                    "sheet_id": sheet_id,
                    "worksheet": ws_title,
                    "row_index": int(idx)
                }
                
                # Adiciona colunas numÃ©ricas/categÃ³ricas aos metadados
                for col in ["Data", "Produto", "Categoria", "RegiÃ£o"]:
                    if col in row:
                        metadata[col.lower()] = str(row[col])
                
                # ID Ãºnico
                doc_id = f"{key}::{idx}"
                
                # Embeddings
                embedding = self.embedder.encode(text).tolist()
                
                # Adiciona ao ChromaDB
                self.collection.add(
                    documents=[text],
                    embeddings=[embedding],
                    metadatas=[metadata],
                    ids=[doc_id]
                )
                indexed += 1
        
        self.client.persist()  # Salva no disco
        return indexed
    
    def _row_to_text(self, row: pd.Series, ws_title: str) -> str:
        """Converte uma linha do DataFrame em texto semÃ¢ntico."""
        parts = [f"Aba: {ws_title}"]
        for col, val in row.items():
            if col.startswith("_"):
                continue
            if pd.notna(val) and str(val).strip():
                parts.append(f"{col}: {val}")
        return " | ".join(parts)
    
    def search(self, query: str, top_k: int = 10, filters: Dict[str, Any] = None) -> List[Dict[str, Any]]:
        """Busca semÃ¢ntica por similaridade."""
        query_embedding = self.embedder.encode(query).tolist()
        
        results = self.collection.query(
            query_embeddings=[query_embedding],
            n_results=top_k,
            where=filters  # Ex: {"produto": "Laptop X1"}
        )
        
        # Formata resultados
        formatted = []
        for i, doc in enumerate(results["documents"][0]):
            formatted.append({
                "text": doc,
                "metadata": results["metadatas"][0][i],
                "distance": results["distances"][0][i] if "distances" in results else None
            })
        return formatted
    
    def clear(self):
        """Limpa o Ã­ndice."""
        self.client.delete_collection("vendas")
        self.collection = self.client.get_or_create_collection(name="vendas")
```

---

### ğŸ¯ SoluÃ§Ã£o 2: **Persistir HistÃ³rico de Conversa**

**OpÃ§Ãµes:**

1. **SQLite Local** (simples, rÃ¡pido)
   ```python
   import sqlite3
   
   def save_message(user_id, role, content):
       conn = sqlite3.connect("data/conversations.db")
       cursor = conn.cursor()
       cursor.execute(
           "INSERT INTO messages (user_id, role, content, timestamp) VALUES (?, ?, ?, ?)",
           (user_id, role, content, datetime.now())
       )
       conn.commit()
       conn.close()
   ```

2. **JSON Files** (mais portÃ¡til)
   ```python
   import json
   from pathlib import Path
   
   def save_conversation(session_id, messages):
       Path("data/conversations").mkdir(exist_ok=True)
       with open(f"data/conversations/{session_id}.json", "w") as f:
           json.dump(messages, f, ensure_ascii=False, indent=2)
   ```

3. **Cloud Storage** (Firebase, Supabase, PostgreSQL)
   - Melhor para produÃ§Ã£o
   - Suporte a mÃºltiplos usuÃ¡rios
   - SincronizaÃ§Ã£o automÃ¡tica

---

### ğŸ¯ SoluÃ§Ã£o 3: **Melhorar Sistema Prompt**

**Novo prompt em `app/prompts.py`:**
```python
SYSTEM_PROMPT_V2 = """
# Quasar Analytics - Assistente de Vendas

VocÃª Ã© um assistente especializado em anÃ¡lise de dados de vendas. Seus dados vÃªm de planilhas do Google Sheets com a seguinte estrutura:

## Colunas DisponÃ­veis:
- **Data**: Formato YYYY-MM-DD (ex: 2024-03-15)
- **ID_TransaÃ§Ã£o**: Formato X-YYYYMM-NNNN (ex: T-202403-0001)
- **Produto**: Nome do produto (ex: Laptop X1, Mouse Ã“ptico)
- **Categoria**: EletrÃ´nicos, AcessÃ³rios, MobiliÃ¡rio, PerifÃ©ricos
- **RegiÃ£o**: Norte, Nordeste, Sul, Sudeste, Centro-Oeste
- **Quantidade**: NÃºmero de unidades vendidas
- **PreÃ§o_UnitÃ¡rio**: Valor em R$ (formato BR: 1.234,56)
- **Receita_Total**: Quantidade Ã— PreÃ§o_UnitÃ¡rio

## Suas Responsabilidades:
1. **Analisar o contexto fornecido** na seÃ§Ã£o "Contexto (planilhas/agregaÃ§Ãµes)"
2. **Calcular mÃ©tricas** quando necessÃ¡rio (totais, mÃ©dias, percentuais)
3. **Formatar respostas** com tabelas Markdown quando apropriado
4. **Ser preciso** com nÃºmeros (usar formato BR: 1.234,56)
5. **Indicar limitaÃ§Ãµes** se o contexto for insuficiente

## Exemplos de Boas Respostas:

### Pergunta: "Quais foram os top 3 produtos em marÃ§o de 2024?"
**Resposta:**
| Produto | Quantidade Vendida | Receita Total |
|---------|-------------------|---------------|
| Laptop X1 | 45 unidades | R$ 215.340,50 |
| Monitor 4K | 32 unidades | R$ 58.920,00 |
| Smartphone ProMax | 28 unidades | R$ 110.450,00 |

### Pergunta: "Como estÃ¡ a performance de vendas?"
**Resposta (quando contexto insuficiente):**
Para fornecer uma anÃ¡lise de performance, preciso saber:
- Qual perÃ­odo vocÃª gostaria de analisar? (mÃªs, trimestre, ano)
- Quer comparar com algum perÃ­odo anterior?
- Alguma regiÃ£o ou produto especÃ­fico?

## Protocolo de Resposta:
1. Leia a seÃ§Ã£o "Contexto" cuidadosamente
2. Se houver dados agregados, use-os prioritariamente
3. Se o contexto for insuficiente, peÃ§a mais detalhes ao usuÃ¡rio
4. Sempre cite nÃºmeros reais dos dados (nunca invente)
5. Use tabelas Markdown para comparaÃ§Ãµes
6. Responda em portuguÃªs brasileiro claro e objetivo

Agora, analise o contexto e responda Ã  pergunta do usuÃ¡rio.
"""
```

---

### ğŸ¯ SoluÃ§Ã£o 4: **Aumentar MAX_TOKENS e Otimizar Contexto**

**MudanÃ§as em `.env.example` e configuraÃ§Ã£o:**
```env
# Aumentar limite de tokens
MAX_TOKENS=4096  # Era 1000

# Permitir mais linhas no contexto
TOP_K_RESULTS=15  # Era 5

# Configurar temperatura para respostas mais precisas
TEMPERATURE=0.3  # Era 0.7 (menor = mais determinÃ­stico)
```

**Atualizar `main.py` para usar configuraÃ§Ã£o:**
```python
# Linha ~485 (busca genÃ©rica)
top_k = int(os.getenv("TOP_K_RESULTS", "15"))  # Aumentado de 5 para 15
rows = loader.search_advanced(last_user_msg, top_k=top_k)
```

---

### ğŸ¯ SoluÃ§Ã£o 5: **Cache Inteligente de Embeddings**

**Problema:** Recomputar embeddings a cada sessÃ£o Ã© custoso.

**SoluÃ§Ã£o:** Persistir ChromaDB e sÃ³ reindexar quando planilhas mudarem.

```python
# Novo arquivo app/cache_manager.py
import hashlib
import json
from pathlib import Path

class CacheManager:
    """Gerencia cache de embeddings baseado em hash dos dados."""
    
    def __init__(self, cache_dir: str = "./data/cache"):
        self.cache_dir = Path(cache_dir)
        self.cache_dir.mkdir(parents=True, exist_ok=True)
    
    def get_data_hash(self, cache: Dict[str, pd.DataFrame]) -> str:
        """Gera hash MD5 do cache atual."""
        # Concatena shapes e colunas de todos os DataFrames
        signature = []
        for key, df in sorted(cache.items()):
            signature.append(f"{key}:{df.shape}:{list(df.columns)}")
        
        combined = "|".join(signature)
        return hashlib.md5(combined.encode()).hexdigest()
    
    def needs_reindex(self, current_hash: str) -> bool:
        """Verifica se precisa reindexar comparando hashes."""
        hash_file = self.cache_dir / "last_index_hash.txt"
        if not hash_file.exists():
            return True
        
        with open(hash_file, "r") as f:
            last_hash = f.read().strip()
        
        return current_hash != last_hash
    
    def save_hash(self, current_hash: str):
        """Salva hash do Ã­ndice atual."""
        hash_file = self.cache_dir / "last_index_hash.txt"
        with open(hash_file, "w") as f:
            f.write(current_hash)
```

---

## ğŸ“‹ PLANO DE IMPLEMENTAÃ‡ÃƒO

### Fase 1: RAG BÃ¡sico (1-2 dias)
- [ ] Adicionar `chromadb` e `sentence-transformers` ao `requirements.txt`
- [ ] Criar `app/rag_engine.py`
- [ ] Integrar `RAGEngine` no `main.py`
- [ ] Testar indexaÃ§Ã£o e busca semÃ¢ntica

### Fase 2: PersistÃªncia (1 dia)
- [ ] Criar `app/cache_manager.py`
- [ ] Implementar hash-based reindexing
- [ ] Adicionar persistÃªncia de histÃ³rico (SQLite ou JSON)

### Fase 3: Melhorias de Prompt (meio dia)
- [ ] Criar `app/prompts.py` com `SYSTEM_PROMPT_V2`
- [ ] Atualizar `abacus_client.py` para usar novo prompt
- [ ] Testar respostas com contexto enriquecido

### Fase 4: OtimizaÃ§Ãµes (1 dia)
- [ ] Aumentar `MAX_TOKENS` para 4096
- [ ] Aumentar `TOP_K_RESULTS` para 15
- [ ] Implementar compressÃ£o de histÃ³rico longo (sumarizaÃ§Ã£o)
- [ ] Adicionar reranking (opcional, com `cohere` ou `sentence-transformers`)

### Fase 5: Testes e ValidaÃ§Ã£o (1 dia)
- [ ] Testes end-to-end com perguntas reais
- [ ] Medir latÃªncia (tempo de resposta)
- [ ] Validar acurÃ¡cia das respostas
- [ ] Ajustar parÃ¢metros de embedding/busca

---

## ğŸš€ EXEMPLO DE USO PÃ“S-IMPLEMENTAÃ‡ÃƒO

### Antes (Sistema Atual):
**UsuÃ¡rio:** _"Quanto vendemos de Laptop X1?"_  
**Bot:** _"Desculpe, nÃ£o encontrei informaÃ§Ãµes suficientes."_  
âŒ **Falha:** Busca por keywords encontrou apenas 5 linhas aleatÃ³rias

### Depois (Com RAG):
**UsuÃ¡rio:** _"Quanto vendemos de Laptop X1?"_  
**Bot (com RAG):**
```
Com base nos dados disponÃ­veis, as vendas de **Laptop X1** foram:

| MÃªs | Quantidade | Receita Total |
|-----|-----------|---------------|
| Jan/2024 | 42 unidades | R$ 201.340,50 |
| Fev/2024 | 38 unidades | R$ 182.920,00 |
| Mar/2024 | 45 unidades | R$ 215.450,00 |
| **Total** | **125 unidades** | **R$ 599.710,50** |

Posso detalhar por regiÃ£o ou comparar com outros produtos?
```
âœ… **Sucesso:** Busca semÃ¢ntica encontrou TODAS as transaÃ§Ãµes de Laptop X1

---

## ğŸ’° ESTIMATIVA DE CUSTOS

### OpÃ§Ã£o 1: ChromaDB Local (Recomendado)
- **Custo:** R$ 0,00
- **Armazenamento:** ~100MB para 10k linhas
- **Performance:** 50-100ms por query
- **LimitaÃ§Ãµes:** NÃ£o escala para milhÃµes de documentos

### OpÃ§Ã£o 2: Pinecone Cloud
- **Custo:** ~R$ 350/mÃªs (plano Starter)
- **Armazenamento:** Ilimitado (dentro do plano)
- **Performance:** 10-30ms por query
- **Vantagens:** Escalabilidade, backups automÃ¡ticos

### OpÃ§Ã£o 3: FAISS + S3 (HÃ­brido)
- **Custo:** ~R$ 20/mÃªs (S3 storage)
- **Performance:** 20-50ms por query
- **Complexidade:** MÃ©dia/Alta

---

## ğŸ¯ MÃ‰TRICAS DE SUCESSO

| MÃ©trica | Antes | Meta PÃ³s-RAG |
|---------|-------|--------------|
| Taxa de respostas corretas | ~40% | >85% |
| Tempo de resposta | 3-5s | <3s |
| Contexto recuperado | 5 linhas | 15-30 linhas |
| PersistÃªncia entre sessÃµes | âŒ NÃ£o | âœ… Sim |
| Busca semÃ¢ntica | âŒ Keywords | âœ… Embeddings |

---

## âš ï¸ RISCOS E MITIGAÃ‡Ã•ES

| Risco | Probabilidade | Impacto | MitigaÃ§Ã£o |
|-------|--------------|---------|-----------|
| Embeddings lentos | MÃ©dia | MÃ©dio | Usar modelo leve (`all-MiniLM-L6-v2`) |
| ChromaDB corrompido | Baixa | Alto | Backups automÃ¡ticos diÃ¡rios |
| MAX_TOKENS excedido | Alta | MÃ©dio | Implementar chunking/sumarizaÃ§Ã£o |
| Custos de API | MÃ©dia | Baixo | Monitorar usage, cache agressivo |

---

## ğŸ“š RECURSOS E REFERÃŠNCIAS

- [ChromaDB Docs](https://docs.trychroma.com/)
- [Sentence Transformers](https://www.sbert.net/)
- [LangChain RAG Tutorial](https://python.langchain.com/docs/use_cases/question_answering/)
- [Streamlit Session State](https://docs.streamlit.io/library/api-reference/session-state)

---

## ğŸ“ PRÃ“XIMOS PASSOS

1. **Revisar este relatÃ³rio** com a equipe
2. **Aprovar tecnologias** (ChromaDB vs alternativas)
3. **Priorizar fases** de implementaÃ§Ã£o
4. **Definir cronograma** e responsÃ¡veis
5. **Iniciar Fase 1** (RAG BÃ¡sico)

---

**ConclusÃ£o:**  
O sistema atual funciona para consultas simples e agregaÃ§Ãµes prÃ©-definidas, mas **nÃ£o escala para perguntas complexas ou dados volumosos**. A implementaÃ§Ã£o de **RAG com ChromaDB** Ã© a soluÃ§Ã£o mais viÃ¡vel para transformar o Quasar em um verdadeiro assistente analÃ­tico inteligente.
