#!/usr/bin/env python3
"""
Teste da API da Abacus com Gemini 2.5 (Flash e Pro) diretamente
"""

import requests
import json

def test_gemini_direct():
    """Testa a API da Abacus usando Gemini 2.5 Flash diretamente."""
    
    api_key = "s2_7ec8cf43a89443bf91d9954336134bf0"
    
    url = "https://routellm.abacus.ai/v1/chat/completions"
    headers = {"Authorization": f"Bearer {api_key}", "Content-Type": "application/json"}
    
    # Teste com diferentes modelos para ver quais est√£o dispon√≠veis
    models_to_test = [
        "gemini-2.5-flash",
        "gemini-2.5-pro",
        "gemini-1.5-flash", 
        "gemini-1.5-pro",
        "gpt-4o",
        "gpt-4o-mini",
        "claude-3-5-sonnet-20241022",
        "route-llm"
    ]
    
    print("üß™ TESTANDO MODELOS DISPON√çVEIS NA ABACUS\n")
    print("="*60)
    
    working_models = []
    
    for model in models_to_test:
        print(f"\nüîç Testando modelo: {model}")
        print("-" * 40)
        
        payload = {
            "model": model,
            "messages": [
                {
                    "role": "user",
                    "content": f"Ol√°! Responda apenas 'Funcionando com {model}' para confirmar."
                }
            ],
            "stream": False,
            "max_tokens": 50
        }
        
        try:
            response = requests.post(url, headers=headers, data=json.dumps(payload), timeout=30)
            
            print(f"Status: {response.status_code}")
            
            if response.status_code == 200:
                result = response.json()
                
                if "choices" in result and len(result["choices"]) > 0:
                    message = result["choices"][0]["message"]["content"]
                    actual_model = result.get("model", "desconhecido")
                    usage = result.get("usage", {})
                    
                    print(f"‚úÖ SUCESSO!")
                    print(f"Modelo solicitado: {model}")
                    print(f"Modelo usado: {actual_model}")
                    print(f"Resposta: {message}")
                    print(f"Tokens: {usage.get('input_tokens', 0)} in, {usage.get('output_tokens', 0)} out")
                    
                    working_models.append({
                        "requested": model,
                        "actual": actual_model,
                        "message": message,
                        "usage": usage
                    })
                else:
                    print("‚ùå Resposta sem choices")
                    
            elif response.status_code == 400:
                error_data = response.json()
                print(f"‚ùå Modelo n√£o suportado: {error_data}")
            elif response.status_code == 422:
                print("‚ùå Par√¢metros inv√°lidos")
            else:
                print(f"‚ùå Erro {response.status_code}: {response.text[:200]}")
                
        except requests.exceptions.Timeout:
            print("‚ùå Timeout na requisi√ß√£o")
        except Exception as e:
            print(f"‚ùå Erro: {str(e)}")
    
    print("\n" + "="*60)
    print("üìä RESUMO DOS RESULTADOS")
    print("="*60)
    
    if working_models:
        print(f"\n‚úÖ {len(working_models)} modelo(s) funcionando:")
        for model_info in working_models:
            print(f"  ‚Ä¢ {model_info['requested']} ‚Üí {model_info['actual']}")
        
        # Destacar o Gemini 2.5 Flash se estiver funcionando
        gemini_flash = next((m for m in working_models if "gemini-2.5-flash" in m['requested']), None)
        if gemini_flash:
            print(f"\nüéØ GEMINI 2.5 FLASH ENCONTRADO!")
            print(f"   Modelo usado: {gemini_flash['actual']}")
            print(f"   Resposta de teste: {gemini_flash['message']}")
            print(f"   Tokens usados: {gemini_flash['usage']}")
            return True
        else:
            print(f"\n‚ö†Ô∏è Gemini 2.5 Flash n√£o encontrado, mas outros modelos funcionam.")
            return False
    else:
        print("\n‚ùå Nenhum modelo funcionou")
        return False

if __name__ == "__main__":
    success = test_gemini_direct()
    
    if success:
        print("\nüéâ Gemini 2.5 Flash est√° funcionando!")
        print("Seu chatbot usar√° especificamente este modelo.")
    else:
        print("\nüí° Verifique quais modelos est√£o dispon√≠veis acima.")
        print("Talvez seja necess√°rio usar um modelo diferente.")